## 可观测性已成为系统必要的属性
### 可观测性已成为系统必要的属性
可观测性概念最早出现于20世纪70年代的电气工程，核心的定义是：A system is said to be observable if, for any possible evolution of state and control vectors, the current state can be estimated using only the information from **outputs**. 其核心思想就是根据外部输出去推断系统目前运行的状态。
![image.png](/img/src/technical/可观测搭建最佳实践/e6d555a437408bdd795d97a509e2962140666588614652341a6d91a81daed4ef.png)
相比传统的告警、监控，可观测性能够以更加“白盒”的方式看透整个复杂的系统，帮助我们更好的观察系统的运行状况，快速定位和解决问题。就像发动机而言，告警只是告诉你发动机是否有问题，而一些包含转速、温度、压力的仪表盘能够帮我们大致确定是哪个部分可能有问题，而真正定位细节问题还需要观察每个部件的传感器数据才行。
![image.png](/img/src/technical/可观测搭建最佳实践/61ed087aff14c62f39adb6f657984753198a72391c4d68b956f468cde76a2ce8.png)
而IT系统经过几十年飞速发展，无论是开发模式、系统架构、部署模式或者基础设施等也经过了好几轮的优化，优化带来了更快的开发、部署效率，但随之而来整个的系统也更加的复杂、开发依赖更多的人和部门、部署模式和运行环境也更加动态和不确定，因此IT行业也已经到了需要更加系统化、体系化进行观测的这一过程。
电气领域的可观测和IT系统中的可观测本质上是为了解决同类的问题：让问题更早的被发现、处理问题的速度会更快、辅助我们的系统设计的更加稳定，而这一切的根本目的，是为了用更低的成本（可观测建设支出）去实现更高的价值（产品稳定、用户体验好）。
### 2022可观测性趋势调研报告
![image.png](/img/src/technical/可观测搭建最佳实践/575b861fe6410500661bf163a13bc73b0ef87bd88c6e042516872c55db700450.png)
今年9月份Newrelic发布2022年可观测趋势调研报告，该报告共采集了1614份问卷，主要针对IT的从业者和决策者，覆盖14个国家。这份报告从可观测部署情况，工具使用情况，投入，好处，挑战以及展望等方面，总结出可观测10个趋势和要点。和大家分享报告中的一些数据以及个人感受，其中都是个人观点，请大家多多指正。

1. 可观测工具使用情况：超过80%的受访者使用4个或者更多的可观测工具；1/3的受访者还是通过手动检测或者通过客户投诉发现问题；7%表示所有的观测数据存储在同一个地方，而且只有5%表示具有成熟的可观测实践经历。

**感受：**多种可观测工具必然会造成效率不高，如何关联分析，自动化和智能化巡检任务将是可观测性平台核心要解决的问题。

2. 可观测展望：**17个**可观测能力组成了成熟完备的可观测实践，主要包括Log、APM、K8s监控、NPM、RUM、AIOps、Alert等，并且受访者普遍希望在2025年都能用上这些技术。

**感受：**各类观测能力代表着不同观测系统的的角度，如何融合17种可观测能力并提供一站式的可观测体验将是未来可观测平台的核心竞争力

3. 可观测数据的好处：提升系统可靠性，提升运维效率，提高主动故障发现的能力，提升用户体验等等
## 可观测性带来的挑战与思考
可观测性能够给我们带来一系列的好处， 但同时也会带来一系列的挑战。接下来将从四个方面去讲述可观测来带的挑战以及自身的一些思考。
### 挑战一：可观测数据量大
![image.png](/img/src/technical/可观测搭建最佳实践/3e3c6110a6797aeb10f191ff71a27230ea299e78303ce1fcae1e26c5d555191a.png)
可观测需要收集系统的各种输出，如：应用日志，Trace，服务指标，系统指标等等；那么第一个挑战就是**数据量爆炸**，以SLS一天大概3000亿次+的访问请求为例，来计算其中涉及的数据量：

- **Logging数据量**：访问日志大概就是3000亿条，按1条访问日志1K的数据量来算，一天的数据量大约是300TB左右，这里还没有包含应用日志。
- **Trace数据量**：Trace数据设置采样 1%，一条Trace大概10个Span，按一个Span大约1K的数据量来算，一天的数据量大概是30TB左右，如果正常来说Trace数据保存3天 ~7天左右，那么大概存储至少稳定在90TB ~210TB左右。
- **Metric数据量**：1个Pod有100个指标，10W个Pod有1KW的数，如果再加上维度信息和时间线，数据量呈几何倍数增长。
### 针对数据量大，数据存储面临的问题
![image.png](/img/src/technical/可观测搭建最佳实践/5db30d60f77db69ea5a7cdb602313a745d330e1b1a8f41cb1ef6af20463e5a1c.png)
在如此庞大的数据量面前，存储也将面临重大的挑战，其中集中在以下四个点：

- **稳定性**：可观测性平台是系统最后一道防火墙。可观测平台的存储服务不稳或者挂了，就没有任何手段还原当时系统的运行情况。
- **写入性能**：面对庞大的数据量下，写入瓶颈将成为可观测平台的短板。写入性能低，容易出现数据分析延迟，造成无法及时发现问题。也容易造成发送堵塞，丢失数据的问题
- **查询效率**：查询效率直接影响了分析效率。AI分析，自动巡检这类分析性的任务都会受到影响，进而影响到发现和定位问题的速度。
- **动态扩容**：面对激增流量情况下能够动态扩充容量。
### 挑战二：关联各类可观测数据，解决数据孤岛的问题
![image.png](/img/src/technical/可观测搭建最佳实践/3fb7f42a08a2d2dd290ed8cb85c203344c202984adb36505003caa5de024f0e0.png)
可观测平台面临的第二个挑战是解决数据孤岛的问题。我们先看一个例子。图中描述的是排查一个线上问题所经历的步骤，首先我们通过告警监测到系统异常，随后通过分析相关联的metric，trace，log，最终定位问题并修复问题。从例子中，我们可以看出整个排查链路长且效率不高，中间可能还需要在几个系统之间来回切换。而造成排障效率不高的核心问题主要原因就是可观测数据间的关系都是靠手工维护，而程序无法通过手工维护的关系去关联分析。那么我们如何去建立可观测数据数据的关系呢？
### 关于如何关联可观测数据的思考
可观测数据间关联如下图所示，我们可以通过Trace中的span ID关联日志，也可以通过Trace的host字段关联Pod的日志，事件。可观测数据关系是通过数据中的字段进行关联，而如果我们通过硬编码方式去关联数据的话，硬编码带来的就是扩展性不高，每次变更都需要重新部署。这也就造成了每当系统新增或者删除关联关系，变更起来繁琐，硬编码的方式还带来了另外一个问题，没有人可以鸟瞰可观测数据间的关系。受UML类图的启发，我们是不是也可以定义一张类UML类图的存储引擎，用来存储对象及其关系，并通过拖拽的方式能够生成观测数据对象以及建立数据间的联系，程序通过API接口查询出对象及其关联的数据进行关联分析。
![image.png](/img/src/technical/可观测搭建最佳实践/377d1956551e8141b25e4ed612913f59e85aa100eeff1a0819e3f28624bbce51.png)

### 挑战三：挖掘可观测数据的价值
通常排障流程也如下图所示：首先从服务自身的的QPS，延迟，错误率等指标开始排查，接着就是业务日志和访问日志，如果查看完还没有排查出问题，就继续排查该服务相关组件的指标和日志，如Pod的指标，Database调用指标，如果此时还没有排查出问题，那么就开始排查和它相关联的下游服务，开启新的一轮循环。上面讲述的只是一个服务排障的流程，那么如果有10个服务呢，整个排障就比较痛苦，如何让排障活动自动化和智能化将是我们面临的第三个挑战。
![image.png](/img/src/technical/可观测搭建最佳实践/232e5e1c11e05922df492f198ef2e031765bf67cddeec218dcd3dfcf7f4ec5fa.png)
### 挑战四：兼顾展示多样化的诉求

![image.png](/img/src/technical/可观测搭建最佳实践/917c5601b5ce7945e4a3314a99b6bb5fe00b8fb42ad7917748db3e0c12a60fd1.png)
可观测带来的第四个挑战，便是应对多样化的展示需求，主要有三个点考虑点：

- 观测角度不一：由于不同的人会有不同的观测系统的角度，这也就导致不同的人想看到数据也会不一样，定制化页面无法适应这种需求，拼装式页面更加适用于适用于可观测场景。
- DrillDown需求旺盛：关联可观测数据才能发挥高价值，页面定制DrillDown能力造成了扩展性不高。配置式的DrillDown能力将在可观测数据展示大放异彩。
- 处理方式要求多：同一种数据在不同的场合有多样化的处理方式，如响应时间，有时需要做预测，有时需要做平均。固化的处理方式应对多样化展示捉襟见肘。
## 可观测平台搭建一些实践
### 开源拼接的可观测平台方案
利用开源组件也是目前搭建可观测平台一种解决方案。通常情况下采集端使用OpenTelemetry，iLogtail，Jaeger等去采集trace，Log，Metric可观测数据，接收端会采用Kafa去缓冲压力以及做数据流的扭转，数据处理层一般会使用OTEL Collector或者自建的数据处理，用于处理特定的可观测的需求，例如：处理业务上的可观测数据，尾部采样，画拓扑图等，最后将数据存储统一存储，以供UI展示。如下图所示：
![image.png](/img/src/technical/可观测搭建最佳实践/644567ca9abba2c7df9d1e0e12f05ee7ccf295e8bcdc6e424698b9dccc62268f.png)
不过利用开源搭建可观测平台的解决方案存在以下两个考虑点：

1. 整个方案涉及到多个组件，如Kafka，Data Processor等，造成运维复杂度高，多一分组件就多一分“危险”。
2. 除了机器外，为了应对之前提到过的挑战，还需要有过相关运维经验的同学，造成了运维成本高
### 可观测平台整体架构图
SLS作为阿里可观测性数据引擎，具备可观测数据日志、指标、分布式链路追踪、事件等的一站式采集和存储。整体架构如图所示：

1. 数据源：数据源以OpenTelemetry为核心，并且支持各类数据形态、设备/端、数据格式的采集，数据被采集进来后进行统一存储。
2. 存储算力：在海量的数据存储下，数据引擎也能提供准实时的查询效率，除了常见的查询和分析能力外，我们还内置了ETL的功能，负责对数据进行清洗和格式化，同时支持对接外部的流计算和离线计算系统。
3. 算法：除了基础的数值算法外，目前我们支持了十多种的异常检测/预测算法，并且还支持流式异常检测；同时也支持使用Scheduled SQL进行数据的编排，帮助我们产生更多新的数据。
4. 价值发掘：价值发掘过程主要通过可视化、告警、交互式分析等人机交互来实现，同时也提供了OpenAPI来对接外部系统或者供用户来实现一些自定义的功能。

![image.png](/img/src/technical/可观测搭建最佳实践/cfc46d9eb89e4b6d81f559cb584af1ff70d87fb5c9e7be1d03fe824530abfbde.png)
### 数据关联 - DataExpression
DataExpression是SLS研发的一套用来关联可观测数据的工具，其想法来源于UML类图的启发，类图(Class diagram)是显示了模型的静态结构，特别是模型中存在的类、类的内部结构以及它们与其他类的关系等，另外它可以动态添加模型以及模型的关系，在DataExpression中，每种可观测数据都可以动态添加字段以及关联，并且提供相应的API的查询数据以及关系。如下图所示：
![image.png](/img/src/technical/可观测搭建最佳实践/e996ac75cb32c8eec3a68445cd4208b9f195fa51bce50cf0ee382ff95716effc.png)
以下是前端页面可以通过DataExpression API查询Trace中的Host对应的关联关系示例：
![image.png](/img/src/technical/可观测搭建最佳实践/59dacef840536be6d0bcb5c39451492b76bbb775a85092d4e40e76321acb41fb.png)
### 扩大可观测范围 - ETL + ScheduleSQL
### ![image.png](/img/src/technical/可观测搭建最佳实践/3a86e05d46c6fd0f8eb32a612d516406371fee3f7e95b3643f23a09b65ba5e19.png)
可观测平台除了定位程序问题外，还可以结合外部数据扩大系统的可观测范围，例如：通过Trace和用户DB可以做用户行为分析，通过Trace和CMDB以及登陆日志，可以做一些攻击检测。而可观测数据想与外部数据要关联，需要对一些针对数据处理的能力，比如：富化，过滤，脱敏，分发等能力，ETL和ScheduleSQL提供了这些能力。
### 多样化展示诉求
![image.png](/img/src/technical/可观测搭建最佳实践/f11d818c2c9fe2059a141d32e7325bdadf917acd24833e2a3e567856d374aa74.png)
在面对数据多样化展示的需求，SLS提供了拼装式的可视化的能力以及复杂可视化能力，用户可以通过SQL语句以及图表完成自定义的观测页面以及复杂的可视化能力。在这里举两个例子展示拼装式的可视化的能力：1. 用户可以通过关联Metric和日志数据，发现版本之间的异常，2. 用户可以通过SLS提供的时序预测能力，发现服务的异常，同时也关联相关的慢服务的信息。
### 智能化 & 自动化 - 自动化寻找问题根因
在面对复杂服务调用出现问题时，我们总是要花费非常多时间去关联数据去确认服务的状态，可疑越多，排查的效率也越低。SLS通过AI算法学习出的因果模型，并结合DataExpression关联的日志或者事件，达到缩小排查范围，提高排查效率的效果。
![image.png](/img/src/technical/可观测搭建最佳实践/6d5965407f5c305b7168b371ea431a007c2918f56874d67a9611b534cb949a09.png)
巡检服务就像巡逻警察一样巡视着整个系统，巡检服务将计算服务方法的动态基线，一旦发现有异常的Trace调用链，将自动调用根因分析的API进行多维度分析，缩小排查范围，用户可以基于分析结果，并结合DataExpression自动关联上的日志或者指标，快速并准确的发现系统出现的异常。
![image.png](/img/src/technical/可观测搭建最佳实践/135a4459c57767864e2bdab0fe3f0553ff0f90f2b224bb66893a555c4d72ea36.png)
## 可观测平台应用实践
### 实践一: 数据 + 拼装式可视化 = 自助式多角度观测
我们可以利用SLS提供的能力完成多角度观测系统的能力。通过我们采集上的数据，各类的数据处理算子以及拼装式的可视化能力，去完成多样的多角度观测页面，例如：通过“服务概览”，我们可以鸟瞰整个系统的运行情况；透过“慢服务分析”，我们可以得知系统何时和和“人”出现了问题；数据库是我们系统必不可少的组件，而通过“数据库分析”可以清楚的知道系统数据库执行情况，未来还有更多观测系统角度可以被发掘出来。
### ![image.png](/img/src/technical/可观测搭建最佳实践/5704e44e5303d956248e215de4c06048f7faa6313c12405c45667085db5bcd13.png)
### 实践二: 智能巡检
用户接入SLS的巡检服务后，可以快速了解系统中出现了多少次异常，异常分布的范围，并结合Data Expression能力，打通关联的日志和指标，协助用户快速的定位和分析问题；同时还可以查看单次请求的根因分析，并给出对应的异常服务的推测的值。
![image.png](/img/src/technical/可观测搭建最佳实践/3a9334e3b32a376cb8f27375227506f7f5eabcd7b5180b30dffebdc5491efc16.png)
## 写在最后
随着系统复杂性的不断提高，排查难度提高，可观测性将成为系统必要的属性，可观测性带来了一系列的好，但同时带来了挑战，一把趁手的工具能够帮助我们轻松的面对困难和挑战，在各类可观测性解决方案，SLS关注于如何提供更好用，更加趁手的工具，让更多的部门/公司快速的搭建好属于自己本身的可观测平台，例如：提供利用AIOps等自动化手段，节省更多的人力，运维提效；使用拼装式的页面以及数据做到自助式的多角度观测系统的能力。我们会持续为大家输出可观测性工具相关的工作内容，敬请期待。

# 概述
在数据分析过程中，数据处理是一个费时费力的过程，数据在什么时候做处理（在落库前、还是落库后）也需要针对不同应用场景做深入探讨。前几年兴起的概念ELT，其与ETL之间的差异本质也是在哪个环节对数据进行处理，关于二者之间的详细对比可参考博文[《ETL vs. ELT: Which is Right for Your Data Warehouse?》](https://www.cdata.com/blog/20210706-etl-vs-elt)。另外，关于数据分析系统schema-on-read和schema-on-write之间的差异也跟此相关，一些对比细节请参考[《Schema on write vs. schema on read》](https://www.elastic.co/blog/schema-on-write-vs-schema-on-read)。个人理解，数据的schema应该包含两个部分：schema的定义、以及将原始数据规整符合schema。最彻底的schema-on-read系统是Splunk（也有极少部分是写入前处理，比如index、host提取）；Elasticsearch也提供了runtime fields的能力来支持schema-on-read场景，不过其更多的是完成了第一个部分，至于数据的规整还是基于Logstash和ingest pipeline在写入之前完成。

这里我们将数据落库之前对其进行处理的方案定义为“数据预处理”，方便往后讨论。数据预处理一般应用在以下场景中：

1. 数据敏感信息安全保障。对于敏感信息的保护是一个重要的议题，基本上是两个方案：落库前脱敏、以及落库后控制访问权限。对于数据分析场景，第一个方案的安全性则更高的。
2. 数据存储、下游使用成本考量。在落库前对数据进行处理，可以对无效数据进行清理，在无需改动上游业务逻辑的前提下，减少存储的压力和成本。同样，在下游存在多个相同是用逻辑的场景中，数据预处理可以减少下游业务的开发成本。

数据预处理存在的缺点和难点：

1. 灵活性相对较差。首先，对于相同的数据的处理需求会不断改变，需要历史数据进行新的处理逻辑的场景在这里是无法实现的。其次，如果上游写入的数据schema出现变动，就需要提前更新好预处理逻辑，影响接入场景的扩展。当然，在类似于系统日志这样的场景中，最新数据的使用权重远远高于历史数据，或者完全不需要长久的历史数据，在数据入库前进行预处理确实是更优的选择。
2. 对于系统的稳定性、可扩展性要求极高。在数据量很大的场景中，如果预处理系统没有足够的性能保证，会导致数据的积压，无法及时处理并入库，最严重的是导致数据缺失。

接下来，我们就选择两个具有代表性的产品，对其数据预处理能力进行讨论。
# Elasticsearch Ingest Pipeline
关于elasticsearch ingest pipeline的介绍与实操，可以参考博文[《Elasticsearch Ingest Pipeline 101: Usage & Setup Made Easy》](https://hevodata.com/learn/elasticsearch-ingest-pipeline/)，下图是对其内部运行的一个剖析。
![image.png](/img/src/product/数据预处理场景概述/12ff39a49541ba146ea8814e213762ac5f56b801895ac3b3086d96cd8a2f98bf.png)

1. Ingest pipeline独立运行在角色为ingest的节点上。
2. Processor是pipline的基本处理单元，比如Grok正则、日期处理等，相当于处理某个特定场景的算子。
3. 错误处理：提供on-failure processor，针对处理过程中发生错误的数据。
4. 提供了数据模拟接口[Simulate Pipeline](https://www.elastic.co/guide/en/elasticsearch/reference/current/simulate-pipeline-api.html)，用于调试数据处理逻辑。
5. Pipeline可以通过设置`_index`字段来实现将数据route到不同的index。所有数据条目都会走完整个pipeline，无法在中途输出。
6. pipeline支持多层嵌套，可以实现逻辑复用和编排。同层级的processor和子pipeline是串联关系。

![image.png](/img/src/product/数据预处理场景概述/4d3e5c98af6a18d718e5aa09024d396dd04590426c9a310d3e1aa16cb97637d6.png)
如下图所示，是一个完整的ingest pipeline应用场景，其中包含了3个pipeline分别对应3个使用场景：A对输入的数据做统一处理；B针对`not level: INFO`的错入日志处理并写入错入日志index；C对于所有数据进行规整，并写入访问日志index。
```json
PUT _ingest/pipeline/A
{
  "description": "Pipeline A",
  "processors": [
    {
      "set": {
        "field": "doc_received_date",
        "value": "{{_ingest.timestamp}}"
      }
    },
    {
      "pipeline": {
        "if": "not level == 'INFO'",
        "name": "B"
      }
    },
    {
      "pipeline": {
        "name": "C"
      }
    }
  ]
}
```

另外一个方面，Logstash作为数据处理组件，也是elastic stack中的一员。关于使用Ingest Node和Logstash的选择可参考博文[《Should I use Logstash or Elasticsearch ingest nodes?》](https://www.elastic.co/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes)。
# Datadog Pipeline
近两年，Datadog在Gartner发布的魔力象限中一直被评为“APM和可观测性”领域的领导者。关于datadog日志数据管理功能的详细体验介绍，请参考博文[《丝滑的日志接入体验 -- Datadog Log Management调研》](https://zhuanlan.zhihu.com/p/572023660)，这里就不做赘述。
![image.png](/img/src/product/数据预处理场景概述/fa83856379989833a8061343856609108d732709a78da15141f04393d94e608f.png)
接下来针对datadog日志处理的Pipeline功能做讨论。Pipeline的完整模块如下图所示：
![image.png](/img/src/product/数据预处理场景概述/c1588bdffcd5c0cd5df18d9642b44069556548cacc9a07b0a254269e4b72351e.png)

1. Preprocess是在pipeline之前的处理过程，解析datadog的内置字段，比如`timestamp`、`host`等。
2. Processor是pipline的基本处理单元，比如Grok正则、日期处理等，相当于处理某个特定场景的算子。
3. 每一个pipeline包含一个匹配条件，比如`source:nginx`，每一条数据会执行与其相匹配的pipeline。如果多个pipeline的匹配条件一样，他们之间则是串联关系，相关数据依次经过各个pipeline进行处理。
4. 支持一层嵌套pipeline，内层pipeline同样包含一个匹配条件，对进入外层pipelin的数据进行选择处理。内层pipeline与平级的processor是串联的关系。
5. Pipeline模版化：针对接入的不同类型日志数据，提供对应的数据处理模版（Integration pipeline）。

如上所述，datadog的pipelines作为一个前置的数据处理服务，每一条数据在入库之前都需要匹配一遍所有的pipeline。其最大优点是UI操作极为便捷，把编排的能力完全融入用户的界面操作中。缺点是灵活性相对较低，虽然支持一层嵌套（相当于数据处理最多包含2层if逻辑判断），不太适用于需要复杂数据处理逻辑的场景。
![image.png](/img/src/product/数据预处理场景概述/508adf92e39258d6eb3f443a7ec8169fc77767db188fe0093d603b6bf1508be8.png)
# 参考链接

- [《ETL vs. ELT: Which is Right for Your Data Warehouse?》](https://www.cdata.com/blog/20210706-etl-vs-elt)
- [《Schema on write vs. schema on read》](https://www.elastic.co/blog/schema-on-write-vs-schema-on-read)
- [《Elasticsearch Ingest Pipeline 101: Usage & Setup Made Easy》 ](https://hevodata.com/learn/elasticsearch-ingest-pipeline/)
- [《Should I use Logstash or Elasticsearch ingest nodes?》 ](https://www.elastic.co/blog/should-i-use-logstash-or-elasticsearch-ingest-nodes)
- [Datadog Pipelines Doc](https://docs.datadoghq.com/logs/log_configuration/pipelines/?tab=source)
- [《丝滑的日志接入体验 -- Datadog Log Management调研》](https://zhuanlan.zhihu.com/p/572023660)
